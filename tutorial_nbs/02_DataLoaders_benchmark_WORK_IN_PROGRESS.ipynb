{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements:\n",
    "\n",
    "* Use X and y\n",
    "* In memory or on disk np.arrays\n",
    "* Use item tfms and/ or batch tfms\n",
    "* Show batch (with tfms)\n",
    "* Good performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:20:44.853668Z",
     "start_time": "2020-03-31T16:20:44.759114Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "ISCOLAB = 'google.colab' in sys.modules\n",
    "if ISCOLAB:\n",
    "    if not os.path.isdir('/content/timeseriesAI2'):\n",
    "        !pip install git+https://github.com/fastai/fastai2 \n",
    "        !pip install git+https://github.com/fastai/fastcore \n",
    "        !pip install pyunpack\n",
    "        !pip install sktime\n",
    "        !git clone https://github.com/timeseriesAI/timeseriesAI2.git\n",
    "        %cd timeseriesAI2\n",
    "    else: \n",
    "        path = !pwd\n",
    "        if path != ['/content/timeseriesAI2']: \n",
    "            %cd timeseriesAI2\n",
    "        !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:20:44.889995Z",
     "start_time": "2020-03-31T16:20:44.861597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:20:58.673344Z",
     "start_time": "2020-03-31T16:20:44.896543Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastai2.torch_core import *\n",
    "from fastai2.data.all import *\n",
    "from fastai2.learner import *\n",
    "from fastai2.metrics import *\n",
    "from fastai2.callback.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:20:58.807234Z",
     "start_time": "2020-03-31T16:20:58.680626Z"
    }
   },
   "outputs": [],
   "source": [
    "from timeseries.imports import *\n",
    "from timeseries.utils import *\n",
    "from timeseries.data import *\n",
    "from timeseries.core import *\n",
    "from timeseries.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:20:58.822844Z",
     "start_time": "2020-03-31T16:20:58.812184Z"
    }
   },
   "outputs": [],
   "source": [
    "def cycle_dl(dl):\n",
    "    for x,y in iter(dl): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:21:02.998132Z",
     "start_time": "2020-03-31T16:20:58.829459Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('../data'): os.makedirs('../data')\n",
    "    \n",
    "X_1000_2_10_in_memory = np.random.rand(1000, 2, 10).astype('float32')\n",
    "np.save('../data/X_1000_2_10.npy', X_1000_2_10_in_memory)\n",
    "X_1000_2_10_on_disk = np.load('../data/X_1000_2_10.npy', mmap_mode='r')\n",
    "\n",
    "X_1000_20_100_in_memory = np.random.rand(1000, 20, 100).astype('float32')\n",
    "np.save('../data/X_1000_20_100.npy', X_1000_20_100_in_memory)\n",
    "X_1000_20_100_on_disk = np.load('../data/X_1000_20_100.npy', mmap_mode='r')\n",
    "\n",
    "X_1000_200_10_in_memory = np.random.rand(1000, 200, 10).astype('float32')\n",
    "np.save('../data/X_1000_200_10.npy', X_1000_200_10_in_memory)\n",
    "X_1000_200_10_on_disk = np.load('../data/X_1000_200_10.npy', mmap_mode='r')\n",
    "\n",
    "X_1000_2_1000_in_memory = np.random.rand(1000, 2, 1000).astype('float32')\n",
    "np.save('../data/X_1000_2_1000.npy', X_1000_2_1000_in_memory)\n",
    "X_1000_2_1000_on_disk = np.load('../data/X_1000_2_1000.npy', mmap_mode='r')\n",
    "\n",
    "X_100_20_1000_in_memory = np.random.rand(100, 20, 1000).astype('float32')\n",
    "np.save('../data/X_100_20_1000.npy', X_100_20_1000_in_memory)\n",
    "X_100_20_1000_on_disk = np.load('../data/X_100_20_1000.npy', mmap_mode='r')\n",
    "\n",
    "X_1000_20_1000_in_memory = np.random.rand(1000, 20, 1000).astype('float32')\n",
    "np.save('../data/X_1000_20_1000.npy', X_1000_2_1000_in_memory)\n",
    "X_1000_20_1000_on_disk = np.load('../data/X_1000_20_1000.npy', mmap_mode='r')\n",
    "\n",
    "X_10000_2_10_in_memory = np.random.rand(10000, 2, 10).astype('float32')\n",
    "np.save('../data/X_10000_2_10.npy', X_10000_2_10_in_memory)\n",
    "X_10000_2_10_on_disk = np.load('../data/X_10000_2_10.npy', mmap_mode='r')\n",
    "\n",
    "# StarLight valid like\n",
    "X_1000_1_1024_in_memory = np.random.rand(1000, 1, 1024).astype('float32')\n",
    "np.save('../data/X_1000_1_1024.npy', X_1000_1_1024_in_memory)\n",
    "X_1000_1_1024_on_disk = np.load('../data/X_1000_1_1024.npy', mmap_mode='r')\n",
    "\n",
    "X_8236_1_1024_in_memory = np.random.rand(8236, 1, 1024).astype('float32')\n",
    "np.save('../data/X_8236_1_1024.npy', X_8236_1_1024_in_memory)\n",
    "X_8236_1_1024_on_disk = np.load('../data/X_8236_1_1024.npy', mmap_mode='r')\n",
    "\n",
    "X_starlight_in_memory = concat(X_1000_1_1024_in_memory, X_8236_1_1024_in_memory)\n",
    "np.save('../data/X_starlight.npy', X_starlight_in_memory)\n",
    "X_starlight_on_disk = np.load('../data/X_starlight.npy', mmap_mode='r')\n",
    "splits = (L(list(np.arange(len(X_1000_1_1024_in_memory)))), \n",
    "          L(list(np.arange(len(X_1000_1_1024_in_memory), len(X_starlight_in_memory)))))\n",
    "\n",
    "y_100 = np.random.randint(0, 10, 100)\n",
    "y_1000 = np.random.randint(0, 10, 1000)\n",
    "y_10000 = np.random.randint(0, 10, 10000)\n",
    "y_8236 = np.random.randint(0, 10, 8236)\n",
    "y_starlight = concat(y_1000, y_8236)\n",
    "\n",
    "Xs_in_memory = [X_1000_20_100_in_memory, X_1000_200_10_in_memory, X_1000_2_1000_in_memory, \n",
    "               X_100_20_1000_in_memory, X_1000_20_1000_in_memory, X_10000_2_10_in_memory, X_8236_1_1024_in_memory]\n",
    "Xs_on_disk = [X_1000_20_100_on_disk, X_1000_200_10_on_disk, X_1000_2_1000_on_disk, \n",
    "               X_100_20_1000_on_disk, X_1000_20_1000_on_disk, X_10000_2_10_on_disk, X_8236_1_1024_on_disk]\n",
    "ys = [y_1000, y_1000, y_1000, y_100, y_1000, y_10000, y_8236]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Native Pytorch dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:21:03.026713Z",
     "start_time": "2020-03-31T16:21:03.004226Z"
    }
   },
   "outputs": [],
   "source": [
    "# Native Pytorch\n",
    "class NumpyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y=None, sel_vars=None, sel_steps=None):\n",
    "        self.X, self.y = X, y\n",
    "        self.sel_vars =  slice(None) if sel_vars is None else sel_vars\n",
    "        self.sel_steps =  slice(None) if sel_steps is None else sel_steps\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.X[idx, self.sel_vars, self.sel_steps], ) if self.y is None \\\n",
    "        else (self.X[idx, self.sel_vars, self.sel_steps], self.y[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1000, 20, 100)        numel:    2,000,000\n",
      "35.5 ms ± 2.89 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "shape: (1000, 200, 10)        numel:    2,000,000\n",
      "37.7 ms ± 4.38 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "shape: (1000, 2, 1000)        numel:    2,000,000\n",
      "39.8 ms ± 1.53 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "shape: (100, 20, 1000)        numel:    2,000,000\n",
      "9.95 ms ± 647 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "\n",
      "shape: (1000, 20, 1000)       numel:   20,000,000\n",
      "93.1 ms ± 8.33 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "shape: (10000, 2, 10)         numel:      200,000\n",
      "349 ms ± 19.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "shape: (8236, 1, 1024)        numel:    8,433,664\n",
      "291 ms ± 13.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x_, y_ in zip(Xs_in_memory, ys):\n",
    "    ds    = NumpyDataset(x_, y_)\n",
    "    dl    = torch.utils.data.DataLoader(dataset=ds, batch_size=128)\n",
    "    print(f'shape: {str(x_.shape):20}   numel: {len(x_.ravel()):12,}')\n",
    "    %timeit cycle_dl(dl)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (8236, 1, 1024)        numel:    8,433,664   bs: 128\n",
      "274 ms ± 20.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "shape: (8236, 1, 1024)        numel:    8,433,664   bs: 1280\n",
      "266 ms ± 9.28 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test larger batch size\n",
    "x_ = X_8236_1_1024_in_memory\n",
    "y_ = y_8236\n",
    "ds    = NumpyDataset(x_, y_)\n",
    "dl    = torch.utils.data.DataLoader(dataset=ds, batch_size=128)\n",
    "xb,yb = next(iter(dl))\n",
    "print(f'shape: {str(x_.shape):20}   numel: {len(x_.ravel()):12,}   bs: {len(xb)}')\n",
    "%timeit cycle_dl(dl)\n",
    "print()\n",
    "\n",
    "ds    = NumpyDataset(x_, y_)\n",
    "dl    = torch.utils.data.DataLoader(dataset=ds, batch_size=1280)\n",
    "xb,yb = next(iter(dl))\n",
    "print(f'shape: {str(x_.shape):20}   numel: {len(x_.ravel()):12,}   bs: {len(xb)}')\n",
    "%timeit cycle_dl(dl)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key learning:** \n",
    "\n",
    "The number of dimensions or length of the time series doesn't have a significant impact on dataloader's performance. \n",
    "\n",
    "Performance is mostly determined by the number of samples, not the number of batches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch native dataloader is pretty fast, although it misses these 3 requirements: \n",
    "\n",
    "* In memory or on disk np.arrays\n",
    "* Use item tfms and/ or batch tfms\n",
    "* Show batch (with tfms)\n",
    "\n",
    "I'll modify the default_collate to allow np.memmap as well. This shouldn't have any impact on performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(dataset,\n",
    "               batch_size=1,\n",
    "               shuffle=False,\n",
    "               sampler=None,\n",
    "               batch_sampler=None,\n",
    "               num_workers=0,\n",
    "               collate_fn=np_collate,\n",
    "               pin_memory=False,\n",
    "               drop_last=False,\n",
    "               timeout=0,\n",
    "               worker_init_fn=None,\n",
    "               multiprocessing_context=None):\n",
    "\n",
    "    return torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        sampler=sampler,\n",
    "        batch_sampler=batch_sampler,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=pin_memory,\n",
    "        drop_last=drop_last,\n",
    "        timeout=timeout,\n",
    "        worker_init_fn=worker_init_fn,\n",
    "        multiprocessing_context=multiprocessing_context)\n",
    "\n",
    "\n",
    "NumpyDataset.dataloader = dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (8236, 1, 1024)        numel:    8,433,664   bs: 128\n",
      "300 ms ± 14.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "shape: (8236, 1, 1024)        numel:    8,433,664   bs: 128\n",
      "303 ms ± 20.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "shape: (8236, 1, 1024)        numel:    8,433,664   bs: 128\n",
      "416 ms ± 22.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test in memory vs on disk arrays\n",
    "x_ = X_8236_1_1024_in_memory\n",
    "y_ = y_8236\n",
    "ds    = NumpyDataset(x_, y_)\n",
    "dl    = torch.utils.data.DataLoader(dataset=ds, batch_size=128)\n",
    "xb,yb = next(iter(dl))\n",
    "print(f'shape: {str(x_.shape):20}   numel: {len(x_.ravel()):12,}   bs: {len(xb)}')\n",
    "%timeit cycle_dl(dl)\n",
    "print()\n",
    "\n",
    "x_ = X_8236_1_1024_in_memory\n",
    "y_ = y_8236\n",
    "ds    = NumpyDataset(x_, y_)\n",
    "dl    = ds.dataloader(batch_size=128)\n",
    "xb,yb = next(iter(dl))\n",
    "print(f'shape: {str(x_.shape):20}   numel: {len(x_.ravel()):12,}   bs: {len(xb)}')\n",
    "%timeit cycle_dl(dl)\n",
    "print()\n",
    "\n",
    "x_ = X_8236_1_1024_on_disk\n",
    "y_ = y_8236\n",
    "ds    = NumpyDataset(x_, y_)\n",
    "dl    = ds.dataloader(batch_size=128)\n",
    "xb,yb = next(iter(dl))\n",
    "print(f'shape: {str(x_.shape):20}   numel: {len(x_.ravel()):12,}   bs: {len(xb)}')\n",
    "%timeit cycle_dl(dl)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key learnings:**\n",
    "\n",
    "- The updated collate function (that allows memmap conversion into a tensor) doesn't negetively impact performance when used with np.ndarrays\n",
    "\n",
    "- data is on disk is 40% slower than in memory, so it's better to pass data in memory if possible. However, performance is still good with data on disk.\n",
    "\n",
    "\n",
    "So we can now meet 3 of the requirements, but cannot still use tfms or show_batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conversion to TS tensor\n",
    "class TSDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.X, self.y = X, y\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None: return (self.X[idx], )\n",
    "        else: return (TSTensor(self.X[idx]), self.y[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "TSDataset.dataloader = dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (8236, 1, 1024)        numel:    8,433,664   bs: 128\n",
      "396 ms ± 18.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "shape: (8236, 1, 1024)        numel:    8,433,664   bs: 128\n",
      "565 ms ± 49.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prior conversion to TSTensor\n",
    "x_ = X_8236_1_1024_on_disk\n",
    "y_ = y_8236\n",
    "\n",
    "ds    = NumpyDataset(x_, y_)\n",
    "dl    = ds.dataloader(batch_size=128)\n",
    "xb,yb = next(iter(dl))\n",
    "print(f'shape: {str(x_.shape):20}   numel: {len(x_.ravel()):12,}   bs: {len(xb)}')\n",
    "%timeit cycle_dl(dl)\n",
    "print()\n",
    "\n",
    "ds    = TSDataset(x_, y_)\n",
    "dl    = ds.dataloader(batch_size=128)\n",
    "xb,yb = next(iter(dl))\n",
    "print(f'shape: {str(x_.shape):20}   numel: {len(x_.ravel()):12,}   bs: {len(xb)}')\n",
    "%timeit cycle_dl(dl)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion to TSTensor makes it is 30-40% slower, so it doesn't seem useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Factory method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (9236, 1, 1024)        numel:    9,457,664   bs: 128\n",
      "3.06 s ± 80.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "x_ = X_starlight_in_memory\n",
    "y_ = y_starlight\n",
    "dls = TSDataLoaders.from_numpy(x_, y_, splitter=IndexSplitter(splits[1]), bs=64, val_bs=128)\n",
    "xb,yb = next(iter(dls.valid))\n",
    "print(f'shape: {str(x_.shape):20}   numel: {len(x_.ravel()):12,}   bs: {len(xb)}')\n",
    "%timeit cycle_dl(dls.valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Datablock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (9236, 1, 1024)        numel:    9,457,664   bs: 128\n",
      "3.08 s ± 42.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "x_ = X_starlight_in_memory\n",
    "y_ = y_starlight\n",
    "getters = [ItemGetter(0), ItemGetter(1)]\n",
    "dblock = DataBlock(blocks=(TSTensorBlock, CategoryBlock),\n",
    "                   getters=getters,\n",
    "                   splitter=IndexSplitter(splits[1]),\n",
    "                   item_tfms=None,\n",
    "                   batch_tfms=None)\n",
    "source = itemify(x_, y_)\n",
    "dls = dblock.dataloaders(source, bs=64, val_bs=128)\n",
    "xb,yb = next(iter(dls.valid))\n",
    "print(f'shape: {str(x_.shape):20}   numel: {len(x_.ravel()):12,}   bs: {len(xb)}')\n",
    "%timeit cycle_dl(dls.valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Datasets + DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NumpyDatasets(FilteredBase):\n",
    "    \"A dataset that creates a tuple from each `tfms`, passed thru `item_tfms`\"\n",
    "    def __init__(self, X=None, y=None, items=None, tfms=None, tls=None, n_inp=None, dl_type=None, **kwargs):\n",
    "        super().__init__(dl_type=dl_type)\n",
    "\n",
    "        #New 4 lines of code\n",
    "        if tls is None:\n",
    "            if items is None: items = itemify(X,) if y is None else itemify(X,y)\n",
    "            assert (tfms is None or len(items[0]) == len(tfms)), f\"n_tfms ({len(tfms)}) doesn't match n_items ({len(items[0])})\"\n",
    "            tfms = None if tfms is None else [[ItemGetter(i)] + L(tfms[i]) for i in range(len(items[0]))]\n",
    "        \n",
    "        self.tls = L(tls if tls else [TfmdLists(items, t, **kwargs) for t in L(ifnone(tfms,[None]))])\n",
    "        self.n_inp = (1 if len(self.tls)==1 else len(self.tls)-1) if n_inp is None else n_inp\n",
    "\n",
    "    def __getitem__(self, it):\n",
    "        res = tuple([tl[it] for tl in self.tls])\n",
    "        return res if is_indexer(it) else list(zip(*res))\n",
    "\n",
    "    def __getattr__(self,k): return gather_attrs(self, k, 'tls')\n",
    "    def __dir__(self): return super().__dir__() + gather_attr_names(self, 'tls')\n",
    "    def __len__(self): return len(self.tls[0])\n",
    "    def __iter__(self): return (self[i] for i in range(len(self)))\n",
    "    def __repr__(self): return coll_repr(self)\n",
    "    def decode(self, o, full=True): return tuple(tl.decode(o_, full=full) for o_,tl in zip(o,tuplify(self.tls, match=o)))\n",
    "    def subset(self, i): return type(self)(tls=L(tl.subset(i) for tl in self.tls), n_inp=self.n_inp)\n",
    "    def _new(self, items, *args, **kwargs): return super()._new(items, tfms=self.tfms, do_setup=False, **kwargs)\n",
    "    def overlapping_splits(self): return self.tls[0].overlapping_splits()\n",
    "    @property\n",
    "    def splits(self): return self.tls[0].splits\n",
    "    @property\n",
    "    def split_idx(self): return self.tls[0].tfms.split_idx\n",
    "    @property\n",
    "    def items(self): return self.tls[0].items\n",
    "    @items.setter\n",
    "    def items(self, v):\n",
    "        for tl in self.tls: tl.items = v\n",
    "\n",
    "    def show(self, o, ctx=None, **kwargs):\n",
    "        for o_,tl in zip(o,self.tls): ctx = tl.show(o_, ctx=ctx, **kwargs)\n",
    "        return ctx\n",
    "\n",
    "    def new_empty(self):\n",
    "        tls = [tl._new([], split_idx=tl.split_idx) for tl in self.tls]\n",
    "        return type(self)(tls=tls, n_inp=self.n_inp)\n",
    "\n",
    "    @contextmanager\n",
    "    def set_split_idx(self, i):\n",
    "        old_split_idx = self.split_idx\n",
    "        for tl in self.tls: tl.tfms.split_idx = i\n",
    "        yield self\n",
    "        for tl in self.tls: tl.tfms.split_idx = old_split_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Key insights:**\n",
    "\n",
    "- Both factory method, datablock API and NumpyDatasets + DataLoaders are all very slow compared to native Pytorch.\n",
    "- Fastai misses these requirements:\n",
    "\n",
    "    * In memory or on disk np.arrays\n",
    "    * Good performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (9236, 1, 1024)        numel:    9,457,664   bs: 64\n",
      "2.49 s ± 64.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "x_ = X_starlight_in_memory\n",
    "y_ = y_starlight\n",
    "\n",
    "tfms  = [[], [Categorize()]]\n",
    "dsets = NumpyDatasets(x_, y_, tfms=tfms, splits=splits)\n",
    "dls   = DataLoaders.from_dsets(dsets.train, dsets.valid, bs=32, val_bs=128)\n",
    "xb,yb = next(iter(dls.valid))\n",
    "print(f'shape: {str(x_.shape):20}   numel: {len(x_.ravel()):12,}   bs: {len(xb)}')\n",
    "%timeit cycle_dl(dls.valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach was suggested by Sylvain Gugger [here](https://forums.fast.ai/t/datablock-with-numpy-input/64848/2?u=oguiza):\n",
    "\n",
    "\n",
    "\"You can create a DataLoaders object from regular PyTorch datasets (though all the visualization methods like show_batch and show_results will fail).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:22:14.981320Z",
     "start_time": "2020-03-31T16:22:04.944792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (8236, 1, 1024)        numel:    8,433,664   bs: 128\n",
      "1.02 s ± 52.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "x_ = X_1000_1_1024_in_memory\n",
    "y_ = y_1000\n",
    "train_ds = NumpyDataset(x_, y_)\n",
    "\n",
    "x_ = X_8236_1_1024_in_memory\n",
    "y_ = y_8236\n",
    "valid_ds = NumpyDataset(x_, y_)\n",
    "dls = DataLoaders.from_dsets(train_ds, valid_ds, batch_size=128)\n",
    "xb,yb = next(iter(dls.valid))\n",
    "print(f'shape: {str(x_.shape):20}   numel: {len(x_.ravel()):12,}   bs: {len(xb)}')\n",
    "%timeit cycle_dl(dls.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:24:50.107680Z",
     "start_time": "2020-03-31T16:24:50.089148Z"
    }
   },
   "outputs": [],
   "source": [
    "class TSDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y=None, sel_vars=None, sel_steps=None):\n",
    "        self.X, self.y = X, y\n",
    "        self.sel_vars =  slice(None) if sel_vars is None else sel_vars\n",
    "        self.sel_steps =  slice(None) if sel_steps is None else sel_steps\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (TSTensor(self.X[idx, self.sel_vars, self.sel_steps], )) if self.y is None \\\n",
    "        else (TSTensor(self.X[idx, self.sel_vars, self.sel_steps]), self.y[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:24:53.524860Z",
     "start_time": "2020-03-31T16:24:51.609216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (8236, 1, 1024)        numel:    8,433,664   bs: 128\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 5995) is killed by signal: Unknown signal: 0. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-beba1cd56ae0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'shape: {str(x_.shape):20}   numel: {len(x_.ravel()):12,}   bs: {len(xb)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cycle_dl(dls.valid)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2312\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2313\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2314\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2315\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</Users/nacho/anaconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1160\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1162\u001b[0;31m         \u001b[0mall_runs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m         \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0mworst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/timeit.py\u001b[0m in \u001b[0;36mrepeat\u001b[0;34m(self, repeat, number)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-88ebb988fd4a>\u001b[0m in \u001b[0;36mcycle_dl\u001b[0;34m(dl)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcycle_dl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastai2/data/load.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandomize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;31m# prime the prefetch loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMP_STATUS_CHECK_INTERVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_put_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mworker_queue_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mworker_queue_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mput\u001b[0;34m(self, obj, block, timeout)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_notempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_notempty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36m_start_thread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'doing self._thread.start()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'... done self._thread.start()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    850\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0m_limbo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_started\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/signal_handling.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mprevious_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 5995) is killed by signal: Unknown signal: 0. "
     ]
    }
   ],
   "source": [
    "x_ = X_1000_1_1024_on_disk\n",
    "y_ = y_1000\n",
    "train_ds = TSDataset(x_, y_)\n",
    "\n",
    "x_ = X_8236_1_1024_on_disk\n",
    "y_ = y_8236\n",
    "valid_ds = TSDataset(x_, y_)\n",
    "dls = DataLoaders.from_dsets(train_ds, valid_ds, batch_size=128)\n",
    "xb,yb = next(iter(dls.valid))\n",
    "print(f'shape: {str(x_.shape):20}   numel: {len(x_.ravel()):12,}   bs: {len(xb)}')\n",
    "%timeit cycle_dl(dls.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:24:19.114839Z",
     "start_time": "2020-03-31T16:24:18.968521Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TSTensor(samples:128, vars:1, len:1024),\n",
       " tensor([5, 3, 1, 2, 6, 4, 8, 2, 6, 2, 1, 4, 5, 9, 6, 5, 6, 1, 8, 4, 3, 7, 9, 3,\n",
       "         8, 8, 2, 8, 4, 4, 5, 8, 9, 3, 2, 0, 9, 4, 5, 8, 9, 1, 1, 0, 0, 4, 4, 2,\n",
       "         6, 1, 6, 3, 8, 1, 7, 8, 8, 5, 9, 1, 2, 4, 6, 5, 0, 7, 3, 2, 2, 4, 6, 7,\n",
       "         9, 4, 1, 3, 8, 2, 8, 5, 7, 9, 0, 4, 0, 8, 5, 2, 3, 1, 3, 8, 6, 7, 4, 7,\n",
       "         1, 0, 7, 1, 8, 3, 8, 5, 9, 6, 4, 8, 5, 8, 5, 5, 8, 6, 4, 4, 8, 3, 5, 6,\n",
       "         1, 3, 0, 6, 9, 0, 4, 1]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (8236, 1, 1024)        numel:    8,433,664   bs: 128\n",
      "304 ms ± 8.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "x_ = X_1000_1_1024_in_memory\n",
    "y_ = y_1000\n",
    "cat = Categorize()\n",
    "cat.setups(y_1000)\n",
    "\n",
    "\n",
    "train_ds = NumpyDataset(x_, y_)\n",
    "train_dl = DataLoader(train_ds, bs=128, shuffle=True, drop_last=True)\n",
    "\n",
    "x_ = X_8236_1_1024_in_memory\n",
    "y_ = y_8236\n",
    "\n",
    "valid_ds = NumpyDataset(x_, y_)\n",
    "valid_dl = DataLoader(valid_ds, bs=128)\n",
    "\n",
    "dls   = DataLoaders(train_dl, valid_dl)\n",
    "xb,yb = next(iter(dls.valid))\n",
    "print(f'shape: {str(x_.shape):20}   numel: {len(x_.ravel()):12,}   bs: {len(xb)}')\n",
    "%timeit cycle_dl(dls.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (8236, 1, 1024)        numel:    8,433,664   bs: 128\n",
      "476 ms ± 21.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "x_ = X_1000_1_1024_in_memory\n",
    "y_ = y_1000\n",
    "\n",
    "train_ds = TSDataset(x_, y_)\n",
    "train_dl = DataLoader(train_ds, bs=128, shuffle=True, drop_last=True)\n",
    "\n",
    "x_ = X_8236_1_1024_in_memory\n",
    "y_ = y_8236\n",
    "\n",
    "valid_ds = TSDataset(x_, y_)\n",
    "valid_dl = DataLoader(valid_ds, bs=128)\n",
    "\n",
    "dls   = DataLoaders(train_dl, valid_dl)\n",
    "xb,yb = next(iter(dls.valid))\n",
    "print(f'shape: {str(x_.shape):20}   numel: {len(x_.ravel()):12,}   bs: {len(xb)}')\n",
    "%timeit cycle_dl(dls.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#11) ['#na#',0,1,2,3,4,5,6,7,8...],\n",
       " 11,\n",
       " defaultdict(int,\n",
       "             {'#na#': 0,\n",
       "              0: 1,\n",
       "              1: 2,\n",
       "              2: 3,\n",
       "              3: 4,\n",
       "              4: 5,\n",
       "              5: 6,\n",
       "              6: 7,\n",
       "              7: 8,\n",
       "              8: 9,\n",
       "              9: 10}))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = Categorize(add_na=True)\n",
    "cat.setups(y_1000)\n",
    "cat.vocab, cat.c, cat.vocab.o2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TensorCategory(np.vectorize(cat.vocab.o2i.get)(y_1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Categorize??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conversion to TS tensor\n",
    "class TSDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.X, self.y = X, y\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None: return (self.X[idx], )\n",
    "        else: return (TSTensor(self.X[idx]), Category(self.y[idx]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "TSDataset.dataloader = dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataLoader??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

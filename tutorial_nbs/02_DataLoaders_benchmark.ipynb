{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:01:54.587829Z",
     "start_time": "2020-03-27T12:01:54.556419Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:02:04.920825Z",
     "start_time": "2020-03-27T12:01:54.596185Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastai2.torch_core import *\n",
    "from fastai2.data.all import *\n",
    "from fastai2.learner import *\n",
    "from fastai2.metrics import *\n",
    "from fastai2.callback.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:02:04.998323Z",
     "start_time": "2020-03-27T12:02:04.927748Z"
    }
   },
   "outputs": [],
   "source": [
    "from timeseries.imports import *\n",
    "from timeseries.utils import *\n",
    "from timeseries.data import *\n",
    "from timeseries.core import *\n",
    "from timeseries.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:02:05.013609Z",
     "start_time": "2020-03-27T12:02:05.004023Z"
    }
   },
   "outputs": [],
   "source": [
    "def cycle_dl(dl):\n",
    "    for x,y in iter(dl): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:10:25.110336Z",
     "start_time": "2020-03-27T12:10:23.486852Z"
    }
   },
   "outputs": [],
   "source": [
    "X_1000_2_10_in_memory = np.random.rand(1000, 2, 10).astype('float32')\n",
    "np.save('../data/X_1000_2_10.npy', X_1000_2_10_in_memory)\n",
    "X_1000_2_10_on_disk = np.load('../data/X_1000_2_10.npy', mmap_mode='r')\n",
    "\n",
    "X_1000_20_100_in_memory = np.random.rand(1000, 20, 100).astype('float32')\n",
    "np.save('../data/X_1000_20_100.npy', X_1000_20_100_in_memory)\n",
    "X_1000_20_100_on_disk = np.load('../data/X_1000_20_100.npy', mmap_mode='r')\n",
    "\n",
    "X_1000_2_1000_in_memory = np.random.rand(1000, 2, 1000).astype('float32')\n",
    "np.save('../data/X_1000_2_1000.npy', X_1000_2_1000_in_memory)\n",
    "X_1000_2_1000_on_disk = np.load('../data/X_1000_2_1000.npy', mmap_mode='r')\n",
    "\n",
    "X_10000_2_10_in_memory = np.random.rand(10000, 2, 10).astype('float32')\n",
    "np.save('../data/X_10000_2_10.npy', X_10000_2_10_in_memory)\n",
    "X_10000_2_10_on_disk = np.load('../data/X_10000_2_10.npy', mmap_mode='r')\n",
    "\n",
    "# StarLight valid like\n",
    "X_1000_1_1024_in_memory = np.random.rand(1000, 1, 1024).astype('float32')\n",
    "np.save('../data/X_1000_1_1024.npy', X_1000_1_1024_in_memory)\n",
    "X_8236_1_1024_on_disk = np.load('../data/X_8236_1_1024.npy', mmap_mode='r')\n",
    "\n",
    "X_8236_1_1024_in_memory = np.random.rand(8236, 1, 1024).astype('float32')\n",
    "np.save('../data/X_8236_1_1024.npy', X_8236_1_1024_in_memory)\n",
    "X_8236_1_1024_on_disk = np.load('../data/X_8236_1_1024.npy', mmap_mode='r')\n",
    "\n",
    "X_starlight_in_memory = concat(X_1000_1_1024_in_memory, X_8236_1_1024_in_memory)\n",
    "np.save('../data/X_starlight.npy', X_starlight_in_memory)\n",
    "X_starlight_on_disk = np.load('../data/X_starlight.npy', mmap_mode='r')\n",
    "splits = (L(list(np.arange(len(X_1000_1_1024_in_memory)))), L(list(np.arange(len(X_1000_1_1024_in_memory), len(X_starlight_in_memory)))))\n",
    "\n",
    "\n",
    "y_1000 = np.random.randint(0, 10, 1000)\n",
    "y_10000 = np.random.randint(0, 10, 10000)\n",
    "y_8236 = np.random.randint(0, 10, 8236)\n",
    "y_starlight = concat(y_1000, y_8236)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:02:06.271972Z",
     "start_time": "2020-03-27T12:02:06.238377Z"
    }
   },
   "outputs": [],
   "source": [
    "# Native Pytorch\n",
    "class NumpyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y=None, sel_vars=None, sel_steps=None):\n",
    "        self.X, self.y = X, y\n",
    "        self.sel_vars =  slice(None) if sel_vars is None else sel_vars\n",
    "        self.sel_steps =  slice(None) if sel_steps is None else sel_steps\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None: return (self.X[idx, self.sel_vars, self.sel_steps], )\n",
    "        else: return (self.X[idx, self.sel_vars, self.sel_steps], self.y[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline: Native Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:02:08.673534Z",
     "start_time": "2020-03-27T12:02:06.280696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 2, 10]) torch.Size([128])\n",
      "28.4 ms ± 211 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "dset    = NumpyDataset(X_1000_2_10_in_memory, y_1000)\n",
    "dloader = torch.utils.data.DataLoader(dataset=dset, batch_size=128, shuffle=True)\n",
    "xb,yb   = next(iter(dloader))\n",
    "print(xb.shape, yb.shape)\n",
    "%timeit cycle_dl(dloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:02:11.567946Z",
     "start_time": "2020-03-27T12:02:08.679858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 20, 100]) torch.Size([128])\n",
      "35.7 ms ± 4.34 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "dset    = NumpyDataset(X_1000_20_100_in_memory, y_1000)\n",
    "dloader = torch.utils.data.DataLoader(dataset=dset, batch_size=128, shuffle=True)\n",
    "xb,yb   = next(iter(dloader))\n",
    "print(xb.shape, yb.shape)\n",
    "%timeit cycle_dl(dloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:02:15.132023Z",
     "start_time": "2020-03-27T12:02:11.575179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 2, 1000]) torch.Size([128])\n",
      "43.7 ms ± 5.24 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "dset    = NumpyDataset(X_1000_2_1000_in_memory, y_1000)\n",
    "dloader = torch.utils.data.DataLoader(dataset=dset, batch_size=128, shuffle=True)\n",
    "xb,yb   = next(iter(dloader))\n",
    "print(xb.shape, yb.shape)\n",
    "%timeit cycle_dl(dloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:02:18.525574Z",
     "start_time": "2020-03-27T12:02:15.139278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 2, 10]) torch.Size([128])\n",
      "434 ms ± 66.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "dset    = NumpyDataset(X_10000_2_10_in_memory, y_10000)\n",
    "dloader = torch.utils.data.DataLoader(dataset=dset, batch_size=128, shuffle=True)\n",
    "xb,yb   = next(iter(dloader))\n",
    "print(xb.shape, yb.shape)\n",
    "%timeit cycle_dl(dloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:02:21.608092Z",
     "start_time": "2020-03-27T12:02:18.535565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1280, 2, 10]) torch.Size([1280])\n",
      "363 ms ± 36.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# test larger batch size\n",
    "dset    = NumpyDataset(X_10000_2_10_in_memory, y_10000)\n",
    "dloader = torch.utils.data.DataLoader(dataset=dset, batch_size=1280, shuffle=True)\n",
    "xb,yb   = next(iter(dloader))\n",
    "print(xb.shape, yb.shape)\n",
    "%timeit cycle_dl(dloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning:** The number of dimensions or length of the time series doesn't have a significant impact on dataloader's performance. Performance is mostly determined by the number of samples, not the number of batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:02:23.750355Z",
     "start_time": "2020-03-27T12:02:21.615418Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 1024]) torch.Size([128])\n",
      "265 ms ± 20.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# StarLight valid like\n",
    "dset    = NumpyDataset(X_8236_1_1024_in_memory, y_8236)\n",
    "dloader = torch.utils.data.DataLoader(dataset=dset, batch_size=128, shuffle=True)\n",
    "xb,yb   = next(iter(dloader))\n",
    "print(xb.shape, yb.shape)\n",
    "%timeit cycle_dl(dloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:02:23.772740Z",
     "start_time": "2020-03-27T12:02:23.756178Z"
    }
   },
   "outputs": [],
   "source": [
    "def dataloader(dataset,\n",
    "               batch_size=1,\n",
    "               shuffle=False,\n",
    "               sampler=None,\n",
    "               batch_sampler=None,\n",
    "               num_workers=0,\n",
    "               collate_fn=np_collate,\n",
    "               pin_memory=False,\n",
    "               drop_last=False,\n",
    "               timeout=0,\n",
    "               worker_init_fn=None,\n",
    "               multiprocessing_context=None):\n",
    "\n",
    "    return torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        sampler=sampler,\n",
    "        batch_sampler=batch_sampler,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=pin_memory,\n",
    "        drop_last=drop_last,\n",
    "        timeout=timeout,\n",
    "        worker_init_fn=worker_init_fn,\n",
    "        multiprocessing_context=multiprocessing_context)\n",
    "\n",
    "\n",
    "NumpyDataset.dataloader = dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:02:23.802254Z",
     "start_time": "2020-03-27T12:02:23.780384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 20, 100])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset    = NumpyDataset(X_1000_20_100_in_memory, y_1000)\n",
    "dloader = dset.dataloader(batch_size=128)\n",
    "xb,yb   = next(iter(dloader))\n",
    "xb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The updated collate function that allows memmap conversion into a tensor doesn't negetively impact performance, while it allows you to pass np.memmap to the dataloader without previous conversion to tensor or np.array. There is a slight delay however if data is on disk vs in memory, so it's better to pass data in memory if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:02:26.755480Z",
     "start_time": "2020-03-27T12:02:23.807886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 20, 100]) torch.Size([128])\n",
      "36.8 ms ± 6.27 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "dset    = NumpyDataset(X_1000_20_100_in_memory, y_1000)\n",
    "dloader = dset.dataloader(batch_size=128, shuffle=True)\n",
    "xb,yb   = next(iter(dloader))\n",
    "print(xb.shape, yb.shape)\n",
    "%timeit cycle_dl(dloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:02:30.250962Z",
     "start_time": "2020-03-27T12:02:26.772865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 20, 100]) torch.Size([128])\n",
      "41.7 ms ± 416 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "dset    = NumpyDataset(X_1000_20_100_on_disk, y_1000)\n",
    "dloader = dset.dataloader(batch_size=128, shuffle=True)\n",
    "xb,yb   = next(iter(dloader))\n",
    "print(xb.shape, yb.shape)\n",
    "%timeit cycle_dl(dloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:02:32.716772Z",
     "start_time": "2020-03-27T12:02:30.258624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 2, 1000]) torch.Size([128])\n",
      "29.9 ms ± 185 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "dset    = NumpyDataset(X_1000_2_1000_in_memory, y_1000)\n",
    "dloader = dset.dataloader(batch_size=128, shuffle=True)\n",
    "xb,yb   = next(iter(dloader))\n",
    "print(xb.shape, yb.shape)\n",
    "%timeit cycle_dl(dloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:02:36.836084Z",
     "start_time": "2020-03-27T12:02:32.722657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 2, 1000]) torch.Size([128])\n",
      "51.5 ms ± 4.79 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "dset    = NumpyDataset(X_1000_2_1000_on_disk, y_1000)\n",
    "dloader = dset.dataloader(batch_size=128, shuffle=True)\n",
    "xb,yb   = next(iter(dloader))\n",
    "print(xb.shape, yb.shape)\n",
    "%timeit cycle_dl(dloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:02:39.422099Z",
     "start_time": "2020-03-27T12:02:36.844549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 2, 10]) torch.Size([128])\n",
      "315 ms ± 27.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "dset    = NumpyDataset(X_10000_2_10_in_memory, y_10000)\n",
    "dloader = dset.dataloader(batch_size=128, shuffle=True)\n",
    "xb,yb   = next(iter(dloader))\n",
    "print(xb.shape, yb.shape)\n",
    "%timeit cycle_dl(dloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:02:43.188130Z",
     "start_time": "2020-03-27T12:02:39.429907Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 2, 10]) torch.Size([128])\n",
      "455 ms ± 35.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "dset    = NumpyDataset(X_10000_2_10_on_disk, y_10000)\n",
    "dloader = dset.dataloader(batch_size=128, shuffle=True)\n",
    "xb,yb   = next(iter(dloader))\n",
    "print(xb.shape, yb.shape)\n",
    "%timeit cycle_dl(dloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:02:45.559415Z",
     "start_time": "2020-03-27T12:02:43.196214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 1024]) torch.Size([128])\n",
      "286 ms ± 26.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# StarLight valid like\n",
    "dset    = NumpyDataset(X_8236_1_1024_in_memory, y_8236)\n",
    "dloader = dset.dataloader(batch_size=128, shuffle=True)\n",
    "xb,yb   = next(iter(dloader))\n",
    "print(xb.shape, yb.shape)\n",
    "%timeit cycle_dl(dloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:02:48.527902Z",
     "start_time": "2020-03-27T12:02:45.566669Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 1024]) torch.Size([128])\n",
      "351 ms ± 18.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# StarLight valid like\n",
    "dset    = NumpyDataset(X_8236_1_1024_on_disk, y_8236)\n",
    "dloader = dset.dataloader(batch_size=128, shuffle=True)\n",
    "xb,yb   = next(iter(dloader))\n",
    "print(xb.shape, yb.shape)\n",
    "%timeit cycle_dl(dloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:02:48.559428Z",
     "start_time": "2020-03-27T12:02:48.539167Z"
    }
   },
   "outputs": [],
   "source": [
    "# conversion to items\n",
    "class NumpyDataset2(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.items = itemify(X,) if y is None else itemify(X,y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.items[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "NumpyDataset2.dataloader = dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion to items doesn't improve performance. Performance is basically the same, so it's not worth it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:02:51.275769Z",
     "start_time": "2020-03-27T12:02:48.569757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 20, 100]) torch.Size([128])\n",
      "31.4 ms ± 1.61 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "dset    = NumpyDataset2(X_1000_20_100_in_memory, y_1000)\n",
    "dloader = dset.dataloader(batch_size=128, shuffle=True)\n",
    "xb,yb = next(iter(dloader))\n",
    "print(xb.shape, yb.shape)\n",
    "%timeit cycle_dl(dloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:02:51.297608Z",
     "start_time": "2020-03-27T12:02:51.282095Z"
    }
   },
   "outputs": [],
   "source": [
    "#conversion to TS tensor\n",
    "class TSDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.X, self.y = X, y\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None: return (self.X[idx], )\n",
    "        else: return (TSTensor(self.X[idx]), self.y[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "TSDataset.dataloader = dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion to TSTensor decreases performance, while it doesn't bring any significant benefit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:02:55.811432Z",
     "start_time": "2020-03-27T12:02:51.303777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.7 ms ± 15.8 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "dset    = TSDataset(X_1000_20_100_in_memory, y_1000)\n",
    "dloader = dset.dataloader(batch_size=128, shuffle=True)\n",
    "xb,yb = next(iter(dloader))\n",
    "print(xb.shape, yb.shape)\n",
    "%timeit cycle_dl(dloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factory method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:11:44.591180Z",
     "start_time": "2020-03-27T12:11:40.726074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 1024]) torch.Size([128])\n",
      "CPU times: user 159 ms, sys: 156 ms, total: 315 ms\n",
      "Wall time: 2.82 s\n"
     ]
    }
   ],
   "source": [
    "dls = TSDataLoaders.from_numpy(X_starlight_in_memory, y_starlight, splitter=IndexSplitter(splits[1]), bs=64, val_bs=128)\n",
    "xb,yb = next(iter(dls.valid))\n",
    "print(xb.shape, yb.shape)\n",
    "%time cycle_dl(dls.valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datablock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:13:56.524398Z",
     "start_time": "2020-03-27T12:13:51.939700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 1024]) torch.Size([128])\n",
      "CPU times: user 166 ms, sys: 153 ms, total: 319 ms\n",
      "Wall time: 3.5 s\n"
     ]
    }
   ],
   "source": [
    "getters = [ItemGetter(0), ItemGetter(1)]\n",
    "dblock = DataBlock(blocks=(TSTensorBlock, CategoryBlock),\n",
    "                   getters=getters,\n",
    "                   splitter=IndexSplitter(splits[1]),\n",
    "                   item_tfms=None,\n",
    "                   batch_tfms=None)\n",
    "source = itemify(X_starlight_in_memory, y_starlight)\n",
    "dls = dblock.dataloaders(source, bs=64, val_bs=128)\n",
    "xb,yb = next(iter(dls.valid))\n",
    "print(xb.shape, yb.shape)\n",
    "%time cycle_dl(dls.valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSDatasets + TSDataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:17:37.973284Z",
     "start_time": "2020-03-27T12:17:37.898555Z"
    }
   },
   "outputs": [],
   "source": [
    "class NumpyDatasets(FilteredBase):\n",
    "    \"A dataset that creates a tuple from each `tfms`, passed thru `item_tfms`\"\n",
    "    def __init__(self, X=None, y=None, items=None, tfms=None, tls=None, n_inp=None, dl_type=None, **kwargs):\n",
    "        super().__init__(dl_type=dl_type)\n",
    "\n",
    "        #New 4 lines of code\n",
    "        if tls is None:\n",
    "            if items is None: items = itemify(X,) if y is None else itemify(X,y)\n",
    "            assert (tfms is None or len(items[0]) == len(tfms)), f\"n_tfms ({len(tfms)}) doesn't match n_items ({len(items[0])})\"\n",
    "            tfms = None if tfms is None else [[ItemGetter(i)] + L(tfms[i]) for i in range(len(items[0]))]\n",
    "        \n",
    "        self.tls = L(tls if tls else [TfmdLists(items, t, **kwargs) for t in L(ifnone(tfms,[None]))])\n",
    "        self.n_inp = (1 if len(self.tls)==1 else len(self.tls)-1) if n_inp is None else n_inp\n",
    "\n",
    "    def __getitem__(self, it):\n",
    "        res = tuple([tl[it] for tl in self.tls])\n",
    "        return res if is_indexer(it) else list(zip(*res))\n",
    "\n",
    "    def __getattr__(self,k): return gather_attrs(self, k, 'tls')\n",
    "    def __dir__(self): return super().__dir__() + gather_attr_names(self, 'tls')\n",
    "    def __len__(self): return len(self.tls[0])\n",
    "    def __iter__(self): return (self[i] for i in range(len(self)))\n",
    "    def __repr__(self): return coll_repr(self)\n",
    "    def decode(self, o, full=True): return tuple(tl.decode(o_, full=full) for o_,tl in zip(o,tuplify(self.tls, match=o)))\n",
    "    def subset(self, i): return type(self)(tls=L(tl.subset(i) for tl in self.tls), n_inp=self.n_inp)\n",
    "    def _new(self, items, *args, **kwargs): return super()._new(items, tfms=self.tfms, do_setup=False, **kwargs)\n",
    "    def overlapping_splits(self): return self.tls[0].overlapping_splits()\n",
    "    @property\n",
    "    def splits(self): return self.tls[0].splits\n",
    "    @property\n",
    "    def split_idx(self): return self.tls[0].tfms.split_idx\n",
    "    @property\n",
    "    def items(self): return self.tls[0].items\n",
    "    @items.setter\n",
    "    def items(self, v):\n",
    "        for tl in self.tls: tl.items = v\n",
    "\n",
    "    def show(self, o, ctx=None, **kwargs):\n",
    "        for o_,tl in zip(o,self.tls): ctx = tl.show(o_, ctx=ctx, **kwargs)\n",
    "        return ctx\n",
    "\n",
    "    def new_empty(self):\n",
    "        tls = [tl._new([], split_idx=tl.split_idx) for tl in self.tls]\n",
    "        return type(self)(tls=tls, n_inp=self.n_inp)\n",
    "\n",
    "    @contextmanager\n",
    "    def set_split_idx(self, i):\n",
    "        old_split_idx = self.split_idx\n",
    "        for tl in self.tls: tl.tfms.split_idx = i\n",
    "        yield self\n",
    "        for tl in self.tls: tl.tfms.split_idx = old_split_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:19:51.883434Z",
     "start_time": "2020-03-27T12:19:45.867401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1024) torch.Size([])\n",
      "CPU times: user 5.72 s, sys: 21.5 ms, total: 5.74 s\n",
      "Wall time: 5.74 s\n"
     ]
    }
   ],
   "source": [
    "tfms = [[], [Categorize()]]\n",
    "dsets = NumpyDatasets(X_starlight_in_memory, y_starlight, tfms=tfms, splits=splits)\n",
    "dls = TSTfmdDL(dsets, bs=64, val_bs=128)\n",
    "xb,yb = next(iter(dls.valid))\n",
    "print(xb.shape, yb.shape)\n",
    "%time cycle_dl(dls.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:19:18.634370Z",
     "start_time": "2020-03-27T12:19:18.596091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TSTensor(vars:1, len:1024), TensorCategory(0))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls = TSTfmdDL(dsets, bs=64, val_bs=128)\n",
    "xb,yb = next(iter(dls.valid))\n",
    "xb, yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T12:19:20.269690Z",
     "start_time": "2020-03-27T12:19:20.142928Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TSTensor(samples:64, vars:1, len:1024),\n",
       " TensorCategory([6, 7, 1, 4, 0, 7, 7, 4, 6, 0, 0, 8, 9, 2, 6, 4, 1, 3, 9, 1, 9, 5, 2, 7,\n",
       "         7, 9, 4, 6, 0, 6, 4, 6, 6, 2, 2, 8, 4, 1, 8, 7, 2, 0, 9, 9, 6, 5, 7, 5,\n",
       "         8, 0, 8, 2, 6, 1, 6, 2, 8, 8, 4, 0, 4, 1, 7, 2]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = dls.one_batch()\n",
    "xb, yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T07:13:38.946517Z",
     "start_time": "2020-03-30T07:13:38.796735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function timeseries.data.np_collate(batch)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T06:28:07.712173Z",
     "start_time": "2020-04-06T06:28:07.706307Z"
    }
   },
   "outputs": [],
   "source": [
    "# default_exp data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "> Helper functions used to download and extract common time series datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T06:28:07.762343Z",
     "start_time": "2020-04-06T06:28:07.730006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width: 100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "# from nbdev.showdoc import *\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width: 100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T06:28:18.441191Z",
     "start_time": "2020-04-06T06:28:07.770224Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from timeseries import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T06:28:18.461317Z",
     "start_time": "2020-04-06T06:28:18.449961Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import tempfile\n",
    "try: from urllib import urlretrieve\n",
    "except ImportError: from urllib.request import urlretrieve\n",
    "import shutil\n",
    "from pyunpack import Archive\n",
    "from scipy.io import arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T06:28:18.488801Z",
     "start_time": "2020-04-06T06:28:18.469652Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def decompress_from_url(url, target_dir=None, verbose=False):\n",
    "    #Download\n",
    "    try:\n",
    "        fname = os.path.basename(url)\n",
    "        tmpdir = tempfile.mkdtemp()\n",
    "        local_comp_fname = os.path.join(tmpdir, fname)\n",
    "        urlretrieve(url, local_comp_fname)\n",
    "    except:\n",
    "        shutil.rmtree(tmpdir)\n",
    "        if verbose: sys.stderr.write(\"Could not download url. Please, check url.\\n\")\n",
    "    \n",
    "    #Decompress\n",
    "    try:\n",
    "        if not os.path.exists(target_dir): os.makedirs(target_dir)\n",
    "        Archive(local_comp_fname).extractall(target_dir)\n",
    "        shutil.rmtree(tmpdir)\n",
    "        return target_dir\n",
    "    except:\n",
    "        shutil.rmtree(tmpdir)\n",
    "        if verbose: sys.stderr.write(\"Could not uncompress file, aborting.\\n\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T06:28:18.527929Z",
     "start_time": "2020-04-06T06:28:18.494938Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def get_UCR_univariate_list():\n",
    "    return [\n",
    "        'ACSF1', 'Adiac', 'AllGestureWiimoteX', 'AllGestureWiimoteY',\n",
    "        'AllGestureWiimoteZ', 'ArrowHead', 'Beef', 'BeetleFly', 'BirdChicken',\n",
    "        'BME', 'Car', 'CBF', 'Chinatown', 'ChlorineConcentration',\n",
    "        'CinCECGTorso', 'Coffee', 'Computers', 'CricketX', 'CricketY',\n",
    "        'CricketZ', 'Crop', 'DiatomSizeReduction',\n",
    "        'DistalPhalanxOutlineAgeGroup', 'DistalPhalanxOutlineCorrect',\n",
    "        'DistalPhalanxTW', 'DodgerLoopDay', 'DodgerLoopGame',\n",
    "        'DodgerLoopWeekend', 'Earthquakes', 'ECG200', 'ECG5000', 'ECGFiveDays',\n",
    "        'ElectricDevices', 'EOGHorizontalSignal', 'EOGVerticalSignal',\n",
    "        'EthanolLevel', 'FaceAll', 'FaceFour', 'FacesUCR', 'FiftyWords',\n",
    "        'Fish', 'FordA', 'FordB', 'FreezerRegularTrain', 'FreezerSmallTrain',\n",
    "        'Fungi', 'GestureMidAirD1', 'GestureMidAirD2', 'GestureMidAirD3',\n",
    "        'GesturePebbleZ1', 'GesturePebbleZ2', 'GunPoint', 'GunPointAgeSpan',\n",
    "        'GunPointMaleVersusFemale', 'GunPointOldVersusYoung', 'Ham',\n",
    "        'HandOutlines', 'Haptics', 'Herring', 'HouseTwenty', 'InlineSkate',\n",
    "        'InsectEPGRegularTrain', 'InsectEPGSmallTrain', 'InsectWingbeatSound',\n",
    "        'ItalyPowerDemand', 'LargeKitchenAppliances', 'Lightning2',\n",
    "        'Lightning7', 'Mallat', 'Meat', 'MedicalImages', 'MelbournePedestrian',\n",
    "        'MiddlePhalanxOutlineAgeGroup', 'MiddlePhalanxOutlineCorrect',\n",
    "        'MiddlePhalanxTW', 'MixedShapesRegularTrain', 'MixedShapesSmallTrain',\n",
    "        'MoteStrain', 'NonInvasiveFetalECGThorax1',\n",
    "        'NonInvasiveFetalECGThorax2', 'OliveOil', 'OSULeaf',\n",
    "        'PhalangesOutlinesCorrect', 'Phoneme', 'PickupGestureWiimoteZ',\n",
    "        'PigAirwayPressure', 'PigArtPressure', 'PigCVP', 'PLAID', 'Plane',\n",
    "        'PowerCons', 'ProximalPhalanxOutlineAgeGroup',\n",
    "        'ProximalPhalanxOutlineCorrect', 'ProximalPhalanxTW',\n",
    "        'RefrigerationDevices', 'Rock', 'ScreenType', 'SemgHandGenderCh2',\n",
    "        'SemgHandMovementCh2', 'SemgHandSubjectCh2', 'ShakeGestureWiimoteZ',\n",
    "        'ShapeletSim', 'ShapesAll', 'SmallKitchenAppliances', 'SmoothSubspace',\n",
    "        'SonyAIBORobotSurface1', 'SonyAIBORobotSurface2', 'StarLightCurves',\n",
    "        'Strawberry', 'SwedishLeaf', 'Symbols', 'SyntheticControl',\n",
    "        'ToeSegmentation1', 'ToeSegmentation2', 'Trace', 'TwoLeadECG',\n",
    "        'TwoPatterns', 'UMD', 'UWaveGestureLibraryAll', 'UWaveGestureLibraryX',\n",
    "        'UWaveGestureLibraryY', 'UWaveGestureLibraryZ', 'Wafer', 'Wine',\n",
    "        'WordSynonyms', 'Worms', 'WormsTwoClass', 'Yoga'\n",
    "    ]\n",
    "\n",
    "test_eq(len(get_UCR_univariate_list()), 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T06:28:18.552576Z",
     "start_time": "2020-04-06T06:28:18.535733Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def get_UCR_multivariate_list():\n",
    "    return [\n",
    "        'ArticularyWordRecognition', 'AtrialFibrillation', 'BasicMotions',\n",
    "        'CharacterTrajectories', 'Cricket', 'DuckDuckGeese', 'EigenWorms',\n",
    "        'Epilepsy', 'ERing', 'EthanolConcentration', 'FaceDetection',\n",
    "        'FingerMovements', 'HandMovementDirection', 'Handwriting', 'Heartbeat',\n",
    "        'InsectWingbeat', 'JapaneseVowels', 'Libras', 'LSST', 'MotorImagery',\n",
    "        'NATOPS', 'PEMS-SF', 'PenDigits', 'PhonemeSpectra', 'RacketSports',\n",
    "        'SelfRegulationSCP1', 'SelfRegulationSCP2', 'SpokenArabicDigits',\n",
    "        'StandWalkJump', 'UWaveGestureLibrary'\n",
    "    ]\n",
    "\n",
    "test_eq(len(get_UCR_multivariate_list()), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T06:28:18.617268Z",
     "start_time": "2020-04-06T06:28:18.558497Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def stack_padding(arr):\n",
    "    def resize(row, size):\n",
    "        new = np.array(row)\n",
    "        new.resize(size)\n",
    "        return new\n",
    "    row_length = max(arr, key=len).__len__()\n",
    "    mat = np.array( [resize(row, row_length) for row in arr] )\n",
    "    return mat\n",
    "\n",
    "\n",
    "from sktime.utils.load_data import load_from_tsfile_to_dataframe\n",
    "def get_UCR_data(dsid, path='.', parent_dir='data/UCR', verbose=False, drop_na=False, on_disk=True):\n",
    "    if verbose: print('Dataset:', dsid)\n",
    "    assert dsid in get_UCR_univariate_list() + get_UCR_multivariate_list(), f'{dsid} is not a UCR dataset'\n",
    "    full_parent_dir = Path(path)/parent_dir\n",
    "    full_tgt_dir = full_parent_dir/dsid\n",
    "    if not all([os.path.isfile(f'{full_parent_dir}/{dsid}/{fn}.npy') for fn in ['X_train', 'X_valid', 'y_train', 'y_valid']]):\n",
    "        if dsid in ['InsectWingbeat', 'DuckDuckGeese']:\n",
    "            if verbose: print('There are problems with the original zip file and data cannot correctly downloaded')\n",
    "            return None, None, None, None\n",
    "        src_website = 'http://www.timeseriesclassification.com/Downloads'\n",
    "        if not os.path.isdir(full_tgt_dir):\n",
    "            if verbose: print(f'Downloading and decompressing data to {full_tgt_dir}...')\n",
    "            decompress_from_url(f'{src_website}/{dsid}.zip', target_dir=full_tgt_dir, verbose=verbose)\n",
    "            if verbose: print('...data downloaded and decompressed')\n",
    "        X_train_df, y_train = load_from_tsfile_to_dataframe(full_tgt_dir/f'{dsid}_TRAIN.ts')\n",
    "        X_valid_df, y_valid = load_from_tsfile_to_dataframe(full_tgt_dir/f'{dsid}_TEST.ts')\n",
    "        X_train_ = []\n",
    "        X_valid_ = []\n",
    "        for i in range(X_train_df.shape[-1]): \n",
    "            X_train_.append(stack_padding(X_train_df[f'dim_{i}'])) # stack arrays even if they have different lengths\n",
    "            X_valid_.append(stack_padding(X_valid_df[f'dim_{i}']))\n",
    "        X_train = np.transpose(np.stack(X_train_, axis=-1), (0, 2, 1)).astype(np.float32)\n",
    "        X_valid = np.transpose(np.stack(X_valid_, axis=-1), (0, 2, 1)).astype(np.float32)\n",
    "#         unique_cats = np.sort(np.unique(y_train))\n",
    "#         o2i = dict(zip(unique_cats, np.arange(len(unique_cats))))\n",
    "#         y_train = np.vectorize(o2i.get)(y_train)\n",
    "#         y_valid = np.vectorize(o2i.get)(y_valid)\n",
    "        np.save(f'{full_tgt_dir}/X_train.npy', X_train)\n",
    "        np.save(f'{full_tgt_dir}/y_train.npy', y_train)\n",
    "        np.save(f'{full_tgt_dir}/X_valid.npy', X_valid)\n",
    "        np.save(f'{full_tgt_dir}/y_valid.npy', y_valid)\n",
    "        delete_all_in_dir(full_tgt_dir, exception='.npy')\n",
    "        \n",
    "    if on_disk: mmap_mode='r+'\n",
    "    else: mmap_mode=None\n",
    "    X_train = np.load(f'{full_tgt_dir}/X_train.npy', mmap_mode=mmap_mode)\n",
    "    y_train = np.load(f'{full_tgt_dir}/y_train.npy', mmap_mode=mmap_mode)\n",
    "    X_valid = np.load(f'{full_tgt_dir}/X_valid.npy', mmap_mode=mmap_mode)\n",
    "    y_valid = np.load(f'{full_tgt_dir}/y_valid.npy', mmap_mode=mmap_mode)\n",
    "\n",
    "    if verbose: \n",
    "        print('X_train:', X_train.shape)\n",
    "        print('y_train:', y_train.shape)\n",
    "        print('X_valid:', X_valid.shape)\n",
    "        print('y_valid:', y_valid.shape, '\\n')\n",
    "        \n",
    "    return X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T06:28:19.900339Z",
     "start_time": "2020-04-06T06:28:18.622720Z"
    }
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "PATH = Path(os.getcwd()).parent # Path to /data/UCR\n",
    "dsids = ['OliveOil', 'AtrialFibrillation'] # univariate and multivariate\n",
    "for dsid in dsids:\n",
    "    tgt_dir = PATH/f'data/UCR/{dsid}'\n",
    "    if os.path.isdir(tgt_dir): shutil.rmtree(tgt_dir)\n",
    "    test_eq(len(get_files(tgt_dir)), 0) # no file left\n",
    "    X_train, y_train, X_valid, y_valid = get_UCR_data(dsid, PATH, parent_dir='data/UCR')\n",
    "    test_eq(len(get_files(tgt_dir, '.npy')), 4)\n",
    "    test_eq(len(get_files(tgt_dir, '.npy')), len(get_files(tgt_dir))) # test no left file/ dir\n",
    "    del X_train, y_train, X_valid, y_valid\n",
    "    start = time.time()\n",
    "    X_train, y_train, X_valid, y_valid = get_UCR_data(dsid, PATH, parent_dir='data/UCR')\n",
    "    elapsed = time.time() - start\n",
    "    test_eq(elapsed < 1, True)\n",
    "    test_eq(X_train.ndim, 3)\n",
    "    test_eq(y_train.ndim, 1)\n",
    "    test_eq(X_valid.ndim, 3)\n",
    "    test_eq(y_valid.ndim, 1)\n",
    "    test_eq(len(get_files(tgt_dir, '.npy')), 4)\n",
    "    test_eq(len(get_files(tgt_dir, '.npy')), len(get_files(tgt_dir))) # test no left file/ dir\n",
    "    test_eq(X_train.ndim, 3)\n",
    "    test_eq(y_train.ndim, 1)\n",
    "    test_eq(X_valid.ndim, 3)\n",
    "    test_eq(y_valid.ndim, 1)\n",
    "    test_eq(X_train.dtype, np.float32)\n",
    "    test_eq(X_train.__class__.__name__, 'memmap')\n",
    "    del X_train, y_train, X_valid, y_valid\n",
    "    X_train, y_train, X_valid, y_valid = get_UCR_data(dsid, PATH, parent_dir='data/UCR', on_disk=False)\n",
    "    test_eq(X_train.__class__.__name__, 'ndarray')\n",
    "    del X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T06:28:20.010917Z",
     "start_time": "2020-04-06T06:28:19.916793Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "r\"\"\"\"Contains definitions of the methods used by the _BaseDataLoaderIter workers to\n",
    "collate samples fetched from dataset into Tensor(s).\n",
    "These **needs** to be in global scope since Py2 doesn't support serializing\n",
    "static methods.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import re\n",
    "from torch._six import container_abcs, string_classes, int_classes\n",
    "\n",
    "np_str_obj_array_pattern = re.compile(r'[SaUO]')\n",
    "\n",
    "\n",
    "def np_convert(data):\n",
    "    r\"\"\"Converts each NumPy array data field into a tensor\"\"\"\n",
    "    elem_type = type(data)\n",
    "    if isinstance(data, torch.Tensor):\n",
    "        return data\n",
    "    elif elem_type.__module__ == 'numpy' and elem_type.__name__ != 'str_' \\\n",
    "            and elem_type.__name__ != 'string_':\n",
    "        # array of string classes and object\n",
    "        if elem_type.__name__ in ['ndarray', 'memmap'] \\\n",
    "                and np_str_obj_array_pattern.search(data.dtype.str) is not None:\n",
    "            return data\n",
    "        return torch.as_tensor(data)\n",
    "    elif isinstance(data, container_abcs.Mapping):\n",
    "        return {key: default_convert(data[key]) for key in data}\n",
    "    elif isinstance(data, tuple) and hasattr(data, '_fields'):  # namedtuple\n",
    "        return elem_type(*(default_convert(d) for d in data))\n",
    "    elif isinstance(data, container_abcs.Sequence) and not isinstance(data, string_classes):\n",
    "        return [default_convert(d) for d in data]\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "\n",
    "np_collate_err_msg_format = (\n",
    "    \"np_collate: batch must contain tensors, numpy arrays, numbers, \"\n",
    "    \"dicts or lists; found {}\")\n",
    "\n",
    "\n",
    "def np_collate(batch):\n",
    "    r\"\"\"Puts each data field into a tensor with outer dimension batch size\"\"\"\n",
    "\n",
    "    elem = batch[0]\n",
    "    elem_type = type(elem)\n",
    "    if isinstance(elem, torch.Tensor):\n",
    "        out = None\n",
    "        if torch.utils.data.get_worker_info() is not None:\n",
    "            # If we're in a background process, concatenate directly into a\n",
    "            # shared memory tensor to avoid an extra copy\n",
    "            numel = sum([x.numel() for x in batch])\n",
    "            storage = elem.storage()._new_shared(numel)\n",
    "            out = elem.new(storage)\n",
    "        return torch.stack(batch, 0, out=out)\n",
    "    elif elem_type.__module__ == 'numpy' and elem_type.__name__ != 'str_' \\\n",
    "            and elem_type.__name__ != 'string_':\n",
    "        elem = batch[0]\n",
    "        if elem_type.__name__ in ['ndarray', 'memmap']:\n",
    "            # array of string classes and object\n",
    "            if np_str_obj_array_pattern.search(elem.dtype.str) is not None:\n",
    "                raise TypeError(np_collate_err_msg_format.format(elem.dtype))\n",
    "            return np_collate([torch.as_tensor(b) for b in batch])\n",
    "        elif elem.shape == ():  # scalars\n",
    "            return torch.as_tensor(batch)\n",
    "    elif isinstance(elem, float):\n",
    "        return torch.tensor(batch, dtype=torch.float64)\n",
    "    elif isinstance(elem, int_classes):\n",
    "        return torch.tensor(batch)\n",
    "    elif isinstance(elem, string_classes):\n",
    "        return batch\n",
    "    elif isinstance(elem, container_abcs.Mapping):\n",
    "        return {key: np_collate([d[key] for d in batch]) for key in elem}\n",
    "    elif isinstance(elem, tuple) and hasattr(elem, '_fields'):  # namedtuple\n",
    "        return elem_type(*(np_collate(samples) for samples in zip(*batch)))\n",
    "    elif isinstance(elem, container_abcs.Sequence): # tuple\n",
    "        transposed = zip(*batch)\n",
    "        return [np_collate(samples) for samples in transposed]\n",
    "\n",
    "    raise TypeError(np_collate_err_msg_format.format(elem_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T06:28:20.085416Z",
     "start_time": "2020-04-06T06:28:20.023432Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.random.rand(2, 3, 4)\n",
    "np.save('../data/a', a)\n",
    "b = np.load('../data/a.npy', mmap_mode='r')\n",
    "test_eq_type(np_convert(a[0]), np_convert(b[0]))\n",
    "test_eq_type(np_collate(a), np_collate(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T06:28:21.982585Z",
     "start_time": "2020-04-06T06:28:20.093943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint()"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current notebook saved.\n",
      "\n",
      "Converted 000_utils.ipynb.\n",
      "Converted 001_core.ipynb.\n",
      "Converted 002_data.ipynb.\n",
      "Converted 100_layers.ipynb.\n",
      "Converted 101_ResNet.ipynb.\n",
      "Converted 102_InceptionTime.ipynb.\n",
      "Converted 103_DeepConvRNN_dev.ipynb.\n",
      "Converted index.ipynb.\n",
      "\n",
      "core.py                        saved          0 s ago\n",
      "utils.py                       saved          0 s ago\n",
      "data.py                        saved          0 s ago\n",
      "DeepConvRNN_dev.py             saved          0 s ago\n",
      "ResNet.py                      saved          0 s ago\n",
      "InceptionTime.py               saved          0 s ago\n",
      "layers.py                      saved          0 s ago\n",
      "\n",
      "Total elapsed time 2 s\n",
      "06-04-2020 06:28:21\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from save_nb import *\n",
    "from nbdev.export import *\n",
    "save_nb()\n",
    "notebook2script()\n",
    "test_eq(last_saved() < 10, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T07:14:14.906133Z",
     "start_time": "2020-03-30T07:14:14.643817Z"
    }
   },
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core\n",
    "\n",
    "> Helper functions used throughout the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T07:14:15.905370Z",
     "start_time": "2020-03-30T07:14:14.924774Z"
    }
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T07:14:27.069336Z",
     "start_time": "2020-03-30T07:14:15.916597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T07:15:14.712695Z",
     "start_time": "2020-03-30T07:14:27.081512Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from fastcore.all import *\n",
    "from fastai2.torch_imports import *\n",
    "from fastai2.torch_core import *\n",
    "from fastai2.data.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T07:15:15.066930Z",
     "start_time": "2020-03-30T07:15:14.720054Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from timeseries.imports import *\n",
    "from timeseries.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T07:15:15.343367Z",
     "start_time": "2020-03-30T07:15:15.073435Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class TSTensor(TensorBase):\n",
    "    '''Returns a tensor of at least 2 dims of type torch.float32 and class TSTensor'''\n",
    "    def __new__(cls, o, dtype=torch.float32, **kwargs): \n",
    "        res = ToType(dtype)(To2DPlusTensor(o))\n",
    "        res.__class__ = cls\n",
    "        res._meta = kwargs\n",
    "        return res\n",
    "\n",
    "    @property\n",
    "    def vars(self): return self.shape[-2]\n",
    "\n",
    "    @property\n",
    "    def len(self): return self.shape[-1]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        res = super().__getitem__(idx)\n",
    "        return retain_type(res, self)\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.ndim >= 3:   return f'TSTensor(samples:{self.shape[-3]}, vars:{self.shape[-2]}, len:{self.shape[-1]})'\n",
    "        elif self.ndim == 2: return f'TSTensor(vars:{self.shape[-2]}, len:{self.shape[-1]})'\n",
    "        elif self.ndim == 1: return f'TSTensor(len:{self.shape[-1]})'\n",
    "        else: return f'TSTensor(float)'\n",
    "\n",
    "    def show(self, ax=None, ctx=None, title=None, **kwargs):\n",
    "        ax = ifnone(ax,ctx)\n",
    "        if ax is None: fig, ax = plt.subplots(**kwargs)\n",
    "        ax.plot(self.T)\n",
    "        ax.axis(xmin=0, xmax=self.shape[-1] - 1)\n",
    "        ax.set_title(title, weight='bold')\n",
    "        plt.tight_layout()\n",
    "        return ax\n",
    "\n",
    "@Transform\n",
    "def ToTSTensor(o:np.ndarray, dtype=torch.float32, **kwargs): \n",
    "    \"\"\" Transforms input to tensor of dtype torch.float32\"\"\"\n",
    "    return TSTensor(o, dtype=dtype, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T07:15:15.593535Z",
     "start_time": "2020-03-30T07:15:15.351916Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class NumpyTensor(TensorBase):\n",
    "\n",
    "    def __new__(cls, o, **kwargs): \n",
    "        res = ToTensor(o)\n",
    "        res.__class__ = cls\n",
    "        res._meta = kwargs\n",
    "        return res\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        res = super().__getitem__(idx)\n",
    "        return retain_type(res, self)\n",
    "\n",
    "    def show(self, ax=None, ctx=None, title=None, **kwargs):\n",
    "        ax = ifnone(ax,ctx)\n",
    "        if ax is None: fig, ax = plt.subplots(**kwargs)\n",
    "        ax.plot(self.T)\n",
    "        ax.axis(xmin=0, xmax=self.shape[-1] - 1)\n",
    "        ax.set_title(title, weight='bold')\n",
    "        plt.tight_layout()\n",
    "        return ax\n",
    "\n",
    "@Transform\n",
    "def ToNumpyTensor(o:np.ndarray): \n",
    "    return NumpyTensor(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T07:15:15.803695Z",
     "start_time": "2020-03-30T07:15:15.605978Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def TSTensorBlock(): \n",
    "    return TransformBlock(item_tfms=ToTSTensor)\n",
    "\n",
    "class TSDataLoaders(DataLoaders):\n",
    "    @classmethod\n",
    "    @delegates(DataLoaders.from_dblock)\n",
    "    def from_numpy(cls, X, y=None, splitter=None, valid_pct=0.2, seed=0, item_tfms=None, batch_tfms=None, **kwargs):\n",
    "        \"Create timeseries dataloaders from arrays (X and y, unless unlabeled)\"\n",
    "        if splitter is None: splitter = RandomSplitter(valid_pct=valid_pct, seed=seed)\n",
    "        getters = [ItemGetter(0), ItemGetter(1)] if y is not None else [ItemGetter(0)]\n",
    "        dblock = DataBlock(blocks=(TSTensorBlock, CategoryBlock),\n",
    "                           getters=getters,\n",
    "                           splitter=splitter,\n",
    "                           item_tfms=item_tfms,\n",
    "                           batch_tfms=batch_tfms)\n",
    "\n",
    "        source = itemify(X) if y is None else itemify(X,y)\n",
    "        return cls.from_dblock(dblock, source, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T07:15:16.076216Z",
     "start_time": "2020-03-30T07:15:15.810236Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class NumpyDatasets(FilteredBase):\n",
    "    \"A dataset that creates a tuple from each `tfms`, passed thru `item_tfms`\"\n",
    "    def __init__(self, X=None, y=None, items=None, tfms=None, tls=None, n_inp=None, dl_type=None, **kwargs):\n",
    "        super().__init__(dl_type=dl_type)\n",
    "\n",
    "        #New 4 lines of code\n",
    "        if tls is None:\n",
    "            if items is None: items = itemify(X,) if y is None else itemify(X,y)\n",
    "            assert (tfms is None or len(items[0]) == len(tfms)), f\"n_tfms ({len(tfms)}) doesn't match n_items ({len(items[0])})\"\n",
    "            tfms = None if tfms is None else [[ItemGetter(i)] + L(tfms[i]) for i in range(len(items[0]))]\n",
    "        \n",
    "        self.tls = L(tls if tls else [TfmdLists(items, t, **kwargs) for t in L(ifnone(tfms,[None]))])\n",
    "        self.n_inp = (1 if len(self.tls)==1 else len(self.tls)-1) if n_inp is None else n_inp\n",
    "\n",
    "    def __getitem__(self, it):\n",
    "        res = tuple([tl[it] for tl in self.tls])\n",
    "        return res if is_indexer(it) else list(zip(*res))\n",
    "\n",
    "    def __getattr__(self,k): return gather_attrs(self, k, 'tls')\n",
    "    def __dir__(self): return super().__dir__() + gather_attr_names(self, 'tls')\n",
    "    def __len__(self): return len(self.tls[0])\n",
    "    def __iter__(self): return (self[i] for i in range(len(self)))\n",
    "    def __repr__(self): return coll_repr(self)\n",
    "    def decode(self, o, full=True): return tuple(tl.decode(o_, full=full) for o_,tl in zip(o,tuplify(self.tls, match=o)))\n",
    "    def subset(self, i): return type(self)(tls=L(tl.subset(i) for tl in self.tls), n_inp=self.n_inp)\n",
    "    def _new(self, items, *args, **kwargs): return super()._new(items, tfms=self.tfms, do_setup=False, **kwargs)\n",
    "    def overlapping_splits(self): return self.tls[0].overlapping_splits()\n",
    "    @property\n",
    "    def splits(self): return self.tls[0].splits\n",
    "    @property\n",
    "    def split_idx(self): return self.tls[0].tfms.split_idx\n",
    "    @property\n",
    "    def items(self): return self.tls[0].items\n",
    "    @items.setter\n",
    "    def items(self, v):\n",
    "        for tl in self.tls: tl.items = v\n",
    "\n",
    "    def show(self, o, ctx=None, **kwargs):\n",
    "        for o_,tl in zip(o,self.tls): ctx = tl.show(o_, ctx=ctx, **kwargs)\n",
    "        return ctx\n",
    "\n",
    "    def new_empty(self):\n",
    "        tls = [tl._new([], split_idx=tl.split_idx) for tl in self.tls]\n",
    "        return type(self)(tls=tls, n_inp=self.n_inp)\n",
    "\n",
    "    @contextmanager\n",
    "    def set_split_idx(self, i):\n",
    "        old_split_idx = self.split_idx\n",
    "        for tl in self.tls: tl.tfms.split_idx = i\n",
    "        yield self\n",
    "        for tl in self.tls: tl.tfms.split_idx = old_split_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T07:15:16.373082Z",
     "start_time": "2020-03-30T07:15:16.082492Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def add_data(dsets, X=None, y=None, test_items=None, rm_tfms=None, with_labels=False):\n",
    "    \"Create a test or unlabeled sets from `items` using validation transforms of `dsets`\"\n",
    "    items = itemify(X,) if y is None else itemify(X, y)\n",
    "    if y is None: with_labels = False\n",
    "    else: with_labels = True\n",
    "    if isinstance(dsets, (Datasets, NumpyDatasets)):\n",
    "        tls = dsets.tls if with_labels else dsets.tls[:dsets.n_inp]\n",
    "        new_tls = [tl._new(items, split_idx=1) for tl in tls]\n",
    "        if rm_tfms is None: rm_tfms = [tl.infer_idx(get_first(items)) for tl in new_tls]\n",
    "        else:               rm_tfms = tuplify(rm_tfms, match=new_tls)\n",
    "        for i,j in enumerate(rm_tfms): new_tls[i].tfms.fs = new_tls[i].tfms.fs[j:]\n",
    "        if isinstance(dsets, Datasets):return Datasets(tls=new_tls)\n",
    "        else: return NumpyDatasets(tls=new_tls)\n",
    "    elif isinstance(dsets, TfmdLists):\n",
    "        new_tl = dsets._new(items, split_idx=1)\n",
    "        if rm_tfms is None: rm_tfms = dsets.infer_idx(get_first(items))\n",
    "        new_tl.tfms.fs = new_tl.tfms.fs[rm_tfms:]\n",
    "        return new_tl\n",
    "    else: raise Exception(f\"This method requires using the fastai library to assemble your data.Expected a `Datasets` or a `TfmdLists` but got {dsets.__class__.__name__}\")\n",
    "\n",
    "NumpyDatasets.add_data = add_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T07:15:16.638637Z",
     "start_time": "2020-03-30T07:15:16.380732Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class TSTfmdDL(TfmdDL): \n",
    "\n",
    "    @property\n",
    "    def vars(self): return self.dataset[0][0].shape[-2]\n",
    "    \n",
    "    @property\n",
    "    def len(self): return self.dataset[0][0].shape[-1]\n",
    "\n",
    "    @delegates(plt.subplots)\n",
    "    def show_batch(self, b=None, max_n=9, nrows=3, ncols=3, figsize=(12, 10), **kwargs):\n",
    "        if b is None: b = self.one_batch()\n",
    "        db = self.decode_batch(b, max_n=max_n)\n",
    "        if nrows is None: \n",
    "            sqrt = math.sqrt(len(db))\n",
    "            rows = min(math.ceil(sqrt), len(db)) \n",
    "        if ncols is None: ncols = len(db) // rnows\n",
    "        fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize,  **kwargs)\n",
    "        for tup, ax in zip(db[:nrows ** 2], [axs] if nrows == 1 else axs.flatten()): \n",
    "            show_tuple(tup, ax=ax)\n",
    "        plt.tight_layout()\n",
    "\n",
    "    def test_dl(self:DataLoaders, test_items, rm_type_tfms=None, with_labels=False, **kwargs):\n",
    "        \"Create a test dataloader from `test_items` using validation transforms of `dls`\"\n",
    "        test = test_set(self.valid, test_items, rm_tfms=rm_type_tfms, with_labels=with_labels\n",
    "                        ) if isinstance(self.valid, (Datasets, NumpyDatasets, TfmdLists)) else test_items\n",
    "        return self.valid.new(test, **kwargs)\n",
    "\n",
    "@delegates(plt.subplots)\n",
    "def show_tuple(tup, ax=None, **kwargs):\n",
    "    \"Display a timeseries plot from a tuple\"\n",
    "    tup[0].show(title='unlabeled' if len(tup) == 1 else tup[1], ax=ax, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T07:15:18.759332Z",
     "start_time": "2020-03-30T07:15:16.644232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint()"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current notebook saved.\n",
      "\n",
      "Converted 000_utils.ipynb.\n",
      "Converted 001_core.ipynb.\n",
      "Converted 002_data.ipynb.\n",
      "Converted 100_layers.ipynb.\n",
      "Converted 101_ResNet.ipynb.\n",
      "Converted 102_InceptionTime.ipynb.\n",
      "Converted index.ipynb.\n",
      "\n",
      "core.py                        saved          0 s ago\n",
      "utils.py                       saved          1 s ago\n",
      "data.py                        saved          0 s ago\n",
      "ResNet.py                      saved          0 s ago\n",
      "InceptionTime.py               saved          0 s ago\n",
      "layers.py                      saved          0 s ago\n",
      "\n",
      "Total elapsed time 2 s\n",
      "30-03-2020 07:15:18\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from save_nb import *\n",
    "from nbdev.export import notebook2script\n",
    "from fastcore.test import test_eq\n",
    "save_nb()\n",
    "notebook2script()\n",
    "test_eq(last_saved() < 10, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
